{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4b5a8a",
   "metadata": {},
   "source": [
    "Kalman Filter, Gerrik\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c7918",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Neural_Decoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPLT\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNeural_Decoding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mND\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNeural_Decoding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bin_spikes\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNeural_Decoding\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bin_output\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'Neural_Decoding'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as NP\n",
    "import pandas as PD\n",
    "import os, scipy, pickle\n",
    "import matplotlib.pyplot as PLT\n",
    "import Neural_Decoding as ND\n",
    "from Neural_Decoding.preprocessing_funcs import bin_spikes\n",
    "from Neural_Decoding.preprocessing_funcs import bin_output\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "from Neural_Decoding.decoders import KalmanFilterDecoder\n",
    "\n",
    "T_B=.05 #Size of time bins in seconds\n",
    "\n",
    "for File_Add in [\"C:/Users/gerri/Coding_Folder/Data_Folder/DS_Final_Data/example_data_hc.pickle\"]:\n",
    "    Mat_Dict=scipy.io.loadmat(File_Add,spmatrix=False)\n",
    "    Keys=list(Mat_Dict.keys())\n",
    "    \"\"\"\n",
    "    spike_times:    When neurons Fired.\n",
    "    vels       :    X and Y velocities\n",
    "    vel_times  :    When vel times were taken.\n",
    "    pos        :    X and Y positions of a cursor\n",
    "    acc        :    X and Y accuracy of cursor\n",
    "    \"\"\"\n",
    "    \n",
    "    #Reformat matlab variables to pandas DF.\n",
    "    DF=dict()\n",
    "    DF[\"Vel_x\"]=Mat_Dict[\"vels\"][:,0]\n",
    "    DF[\"Vel_y\"]=Mat_Dict[\"vels\"][:,1]\n",
    "    DF[\"Vel_t\"]=NP.concat(Mat_Dict[\"vel_times\"])\n",
    "    DF[\"Pos_x\"]=Mat_Dict[\"pos\"][:,0]\n",
    "    DF[\"Pos_y\"]=Mat_Dict[\"pos\"][:,1]\n",
    "    DF[\"acc_x\"]=Mat_Dict[\"acc\"][:,0]\n",
    "    DF[\"acc_y\"]=Mat_Dict[\"acc\"][:,1]\n",
    "    Spike_Times=NP.sort(NP.reshape(Mat_Dict[\"spike_times\"],shape=-1))\n",
    "    PD.DataFrame(DF)\n",
    "\n",
    "    neural_data=bin_spikes(\n",
    "        spike_times=DF[\"Vel_t\"],\n",
    "        dt=T_B,\n",
    "        wdw_start=DF[\"Vel_t\"][0],\n",
    "        wds_end=DF[\"Vel_t\"][-1])\n",
    "    \n",
    "    vels_binned=bin_output(\n",
    "        outputs=Mat_Dict[\"vels\"],\n",
    "        output_times=DF[\"Vel_t\"],\n",
    "        dt=         T_B,            #Time bin size==0.05 seconds\n",
    "        wdw_start=  DF[\"Vel_t\"][0], #Start at first sample\n",
    "        wdw_end=    DF[\"Vel_t\"][-1],#End at last sample\n",
    "        downsample_factor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02014b",
   "metadata": {},
   "source": [
    "As can be seen above, both files contain the same variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as NP\n",
    "import pandas as PD\n",
    "import os, scipy, pickle\n",
    "import matplotlib.pyplot as PLT\n",
    "import Neural_Decoding as ND\n",
    "from Neural_Decoding.preprocessing_funcs import bin_spikes\n",
    "from Neural_Decoding.preprocessing_funcs import bin_output\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "from Neural_Decoding.decoders import KalmanFilterDecoder\n",
    "\n",
    "with open(\"C:/Users/gerri/Coding_Folder/Data_Folder/DS_Final_Data/example_data_hc.pickle\") as File:\n",
    "    neural_data,pos_binned=pickle.load(File,encoding='latin1')\n",
    "    print(f\"neural_data \\n{NP.shape(neural_data)}\"+\"\\n\"+f\"pos_binned \\n{NP.shape(pos_binned)}\")\n",
    "    \n",
    "    \"\"\"\n",
    "    neural_data:    When neurons Fired. num_bins x num_neurons. 1 when fired, 0 when not.\n",
    "    pos_binned       :    X and Y velocities\n",
    "    \"\"\"\n",
    "    lag=0\n",
    "    nd_sum=NP.nansum(neural_data,axis=0) #Total number of spikes of each neuron\n",
    "    nd_mean=NP.mean(nd_sum)\n",
    "    nd_std=NP.std(nd_sum)\n",
    "    nd_thresh=nd_mean-nd_std*2\n",
    "    rmv_nrn=NP.where(nd_sum<100) #Find neurons who have less than 2 std of dataset. Gerrik\n",
    "    rmv_nrn_std=NP.where(nd_sum<nd_thresh) #Find neurons who have less than 100 spikes total\n",
    "    print(f\"rmv_nrn \\n{NP.shape(rmv_nrn)}\"+\"\\n\"+f\"rmv_nrn_std \\n{NP.shape(rmv_nrn_std)}\")\n",
    "\n",
    "    Covariate=NP.delete(neural_data,rmv_nrn,1)\n",
    "    Covariate_G=NP.delete(neural_data,rmv_nrn,1)\n",
    "\n",
    "    temp=NP.diff(pos_binned,axis=0)\n",
    "    vels_binned=NP.concatenate((temp,temp[-1:,:]),axis=0)\n",
    "\n",
    "    #We now determine acceleration\n",
    "    temp2=NP.diff(vels_binned,axis=0)\n",
    "    acc_binned=NP.concatenate((temp2,temp2[-1:,:]),axis=0)\n",
    "\n",
    "    y_kf=NP.concatenate((pos_binned,vels_binned,acc_binned),axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bar_ilan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
