{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646e5865",
   "metadata": {},
   "source": [
    "# Debugging Data Loading and Structure\n",
    "This notebook explores the raw data files, their internal structure, and the preprocessing pipeline outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9141d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 .mat files:\n",
      "  - /Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/hc_data_raw.mat\n",
      "\n",
      "--- Structure of /Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/hc_data_raw.mat ---\n",
      "Keys: ['__header__', '__version__', '__globals__', 'spike_times', 'pos_times', 'pos']\n",
      "\n",
      "spike_times:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (58, 1)\n",
      "  Dtype: object\n",
      "\n",
      "pos_times:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (1, 219089)\n",
      "  Dtype: float64\n",
      "\n",
      "pos:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (219089, 2)\n",
      "  Dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "# List all .mat files in the current directory\n",
    "mat_files = [\"/Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/hc_data_raw.mat\"]\n",
    "print(f\"Found {len(mat_files)} .mat files:\")\n",
    "for f in mat_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Load and analyze the first .mat file\n",
    "if mat_files:\n",
    "    mat_path = mat_files[0]\n",
    "    mat_data = sio.loadmat(mat_path)\n",
    "    \n",
    "    print(f\"\\n--- Structure of {mat_path} ---\")\n",
    "    print(f\"Keys: {list(mat_data.keys())}\")\n",
    "    \n",
    "    # Analyze each variable\n",
    "    for key in mat_data.keys():\n",
    "        if not key.startswith('__'):  # Skip metadata\n",
    "            value = mat_data[key]\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Type: {type(value)}\")\n",
    "            print(f\"  Shape: {value.shape if hasattr(value, 'shape') else 'N/A'}\")\n",
    "            print(f\"  Dtype: {value.dtype if hasattr(value, 'dtype') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4dc8a8",
   "metadata": {},
   "source": [
    "## Data Exploration: Hippocampus Dataset\n",
    "Load and inspect the structure of the Hippocampus raw data file (`hc_data_raw.mat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4036b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 .mat files:\n",
      "  - /Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/m1_data_raw.mat\n",
      "\n",
      "--- Structure of /Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/m1_data_raw.mat ---\n",
      "Keys: ['__header__', '__version__', '__globals__', 'spike_times', 'vels', 'vel_times', 'pos', 'acc']\n",
      "\n",
      "spike_times:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (164, 1)\n",
      "  Dtype: object\n",
      "\n",
      "vels:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (1264999, 2)\n",
      "  Dtype: float64\n",
      "\n",
      "vel_times:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (1264999, 1)\n",
      "  Dtype: float64\n",
      "\n",
      "pos:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (1264999, 2)\n",
      "  Dtype: float64\n",
      "\n",
      "acc:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (1264999, 2)\n",
      "  Dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mat_files = [\"/Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/m1_data_raw.mat\"]\n",
    "print(f\"Found {len(mat_files)} .mat files:\")\n",
    "for f in mat_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Load and analyze the first .mat file\n",
    "if mat_files:\n",
    "    mat_path = mat_files[0]\n",
    "    mat_data = sio.loadmat(mat_path)\n",
    "    \n",
    "    print(f\"\\n--- Structure of {mat_path} ---\")\n",
    "    print(f\"Keys: {list(mat_data.keys())}\")\n",
    "    \n",
    "    # Analyze each variable\n",
    "    for key in mat_data.keys():\n",
    "        if not key.startswith('__'):  # Skip metadata\n",
    "            value = mat_data[key]\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Type: {type(value)}\")\n",
    "            print(f\"  Shape: {value.shape if hasattr(value, 'shape') else 'N/A'}\")\n",
    "            print(f\"  Dtype: {value.dtype if hasattr(value, 'dtype') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28619016",
   "metadata": {},
   "source": [
    "## Data Exploration: Motor Cortex Dataset\n",
    "Load and inspect the structure of the M1 raw data file (`m1_data_raw.mat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b38c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 17:46:57,005 - main.py - run_preprocessing - INFO - Preprocessing data...\n",
      "2026-01-23 17:46:57,008 - main.py - run_preprocessing - DEBUG - Binning spikes with bin_size=0.050\n",
      "2026-01-23 17:47:15,406 - main.py - run_preprocessing - DEBUG - Creating train/test split with bins_before=0, bins_after=0, bins_current=1\n",
      "2026-01-23 17:47:15,461 - main.py - run_preprocessing - INFO - Preprocessing complete: X_train shape=(17710, 164), X_test shape=(5060, 164)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: shape=(17710, 164), dtype=float64, min=0.0, max=13.0\n",
      "X_test: shape=(5060, 164), dtype=float64, min=0.0, max=12.0\n",
      "y_train: shape=(17710, 2), dtype=float64, min=-31.79176907599171, max=33.244782071208746\n",
      "y_test: shape=(5060, 2), dtype=float64, min=-29.870950396348764, max=32.23741366414379\n"
     ]
    }
   ],
   "source": [
    "# Load, preprocess, and analyze output structure\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add 'src' directory to sys.path to allow importing neural_decoding module\n",
    "current_dir = Path(os.getcwd())\n",
    "src_path = current_dir.parent / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from neural_decoding.data.loader import load_dataset\n",
    "from neural_decoding.main import run_preprocessing, DEFAULT_BIN_SIZE, DEFAULT_START_TIME\n",
    "\n",
    "# Path to your .mat data file (adjusted for notebook location in 'notebooks/')\n",
    "mat_path = Path(\"../data/raw/m1_data_raw.mat\")\n",
    "\n",
    "# Check if file exists to avoid confusion\n",
    "if not mat_path.exists():\n",
    "    # Try absolute path if relative fails (fallback)\n",
    "    mat_path = Path(\"/Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/m1_data_raw.mat\")\n",
    "\n",
    "# Load data\n",
    "raw_data = load_dataset(mat_path)\n",
    "neural_data = raw_data[\"spike_times\"]\n",
    "outputs = (raw_data[\"outputs\"], raw_data[\"output_times\"])\n",
    "\n",
    "# Preprocess data\n",
    "config = {\"bin_size\": DEFAULT_BIN_SIZE, \"start_time\": DEFAULT_START_TIME}\n",
    "X_train, X_test, y_train, y_test = run_preprocessing(neural_data, outputs, config)\n",
    "\n",
    "# Analyze output structure\n",
    "def print_array_info(name, arr):\n",
    "    print(f\"{name}: shape={arr.shape}, dtype={arr.dtype}, min={arr.min()}, max={arr.max()}\")\n",
    "\n",
    "print_array_info(\"X_train\", X_train)\n",
    "print_array_info(\"X_test\", X_test)\n",
    "print_array_info(\"y_train\", y_train)\n",
    "print_array_info(\"y_test\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b5ae6",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline Check\n",
    "Run the full preprocessing pipeline on the M1 dataset and verify the shapes of training and test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587632f",
   "metadata": {},
   "source": [
    "X_train: shape=(17710, 164), dtype=float64, min=0.0, max=13.0\n",
    "Training feature matrix. 17,710 time bins (samples), 164 neurons (features). Each value is the binned spike count for a neuron in a time bin.\n",
    "\n",
    "X_test: shape=(5060, 164), dtype=float64, min=0.0, max=12.0\n",
    "Test feature matrix. 5,060 time bins, 164 neurons. Same format as X_train, but for the test set.\n",
    "\n",
    "y_train: shape=(17710, 2), dtype=float64, min=-31.79..., max=33.24...\n",
    "Training target/output matrix. 17,710 samples, 2 output variables (e.g., position X and Y). Values are the behavioral measurements aligned to each time bin.\n",
    "\n",
    "y_test: shape=(5060, 2), dtype=float64, min=-29.87..., max=32.23...\n",
    "Test target/output matrix. 5,060 samples, 2 output variables. Same format as y_train, but for the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72568983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. data['spike_times'] (Loaded from .mat):\n",
      "   Type: <class 'numpy.ndarray'>\n",
      "   Shape: (164, 1)\n",
      "   Dtype: object\n",
      "   Content example (first element): [[4.47300000e-01 4.91366667e-01 1.31610000e+00 ... 1.30698600e+03\n",
      "  1.30727720e+03 1.30728827e+03]]\n",
      "   Type of first element: <class 'numpy.ndarray'>\n",
      "\n",
      "2. Processing loop (Transformation):\n",
      "   Raw element shape: (1, 15215)\n",
      "   Converted to np.array shape: (1, 15215)\n",
      "   Flattened shape: (15215,)\n",
      "   First 5 spike times: [0.4473     0.49136667 1.3161     2.5238     2.80613333]\n",
      "\n",
      "3. spike_times (Final List):\n",
      "   Type: <class 'list'>\n",
      "   Length: 164\n",
      "   Type of element 0: <class 'numpy.ndarray'>\n",
      "   Shape of element 0: (15215,)\n"
     ]
    }
   ],
   "source": [
    "# Analyze detailed structure of spike times loading\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw .mat data\n",
    "mat_path = Path(\"../data/raw/m1_data_raw.mat\")\n",
    "if not mat_path.exists():\n",
    "    mat_path = Path(\"/Users/kidus/Desktop/Neural_Decoding/Neural_Decoding_DS_Final/data/raw/m1_data_raw.mat\")\n",
    "data = sio.loadmat(mat_path)\n",
    "\n",
    "print(\"1. data['spike_times'] (Loaded from .mat):\")\n",
    "spike_times_raw = data[\"spike_times\"]\n",
    "print(f\"   Type: {type(spike_times_raw)}\")\n",
    "print(f\"   Shape: {spike_times_raw.shape}\")\n",
    "print(f\"   Dtype: {spike_times_raw.dtype}\")\n",
    "print(f\"   Content example (first element): {spike_times_raw[0, 0]}\")\n",
    "print(f\"   Type of first element: {type(spike_times_raw[0, 0])}\")\n",
    "\n",
    "print(\"\\n2. Processing loop (Transformation):\")\n",
    "# Simulate the loop for the first neuron\n",
    "i = 0\n",
    "element = spike_times_raw[i, 0]\n",
    "print(f\"   Raw element shape: {element.shape}\")\n",
    "as_array = np.array(element)\n",
    "print(f\"   Converted to np.array shape: {as_array.shape}\")\n",
    "flattened = as_array.flatten()\n",
    "print(f\"   Flattened shape: {flattened.shape}\")\n",
    "print(f\"   First 5 spike times: {flattened[:5]}\")\n",
    "\n",
    "print(\"\\n3. spike_times (Final List):\")\n",
    "spike_times = [\n",
    "    np.array(spike_times_raw[i, 0]).flatten()\n",
    "    for i in range(spike_times_raw.shape[0])\n",
    "]\n",
    "print(f\"   Type: {type(spike_times)}\")\n",
    "print(f\"   Length: {len(spike_times)}\")\n",
    "print(f\"   Type of element 0: {type(spike_times[0])}\")\n",
    "print(f\"   Shape of element 0: {spike_times[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15395f90",
   "metadata": {},
   "source": [
    "## Deep Dive: Spike Times Loading and Formatting\n",
    "Detailed analysis of how `spike_times` are extracted and transformed from the raw MATLAB cell array into Python list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63c52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG-GAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
